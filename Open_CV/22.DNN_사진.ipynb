{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용할 모델 파일명\n",
    "model_name = 'opencv_data/res10_300x300_ssd_iter_140000.caffemodel'\n",
    "\n",
    "# 모델 내의 신경망 구조 정보 파일명\n",
    "prototxt_name = 'opencv_data/deploy.prototxt.txt'\n",
    "\n",
    "# 얼굴이라고 인정할 최소 정확도\n",
    "min_confidence = 0.2\n",
    "\n",
    "# 사용할 파일이름\n",
    "file_name = 'opencv_data/image/marathon_01.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지를 불러온다\n",
    "frame = cv2.imread(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "width : 1440\n",
      "height : 1440\n",
      "channels : 3\n"
     ]
    }
   ],
   "source": [
    "# 정보를 확인한다.\n",
    "print(f'width : {frame.shape[1]}')\n",
    "print(f'height : {frame.shape[0]}')\n",
    "print(f'channels : {frame.shape[2]}')\n",
    "\n",
    "# 원본 이미지의 가로 세로 길이\n",
    "width = frame.shape[1]\n",
    "height = frame.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('Original frame', frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 얼굴인식 작업\n",
    "# 사용할 모델을 불러온다.\n",
    "model = cv2.dnn.readNetFromCaffe(prototxt_name, model_name)\n",
    "\n",
    "# prototxt 파일에 이미지가 300 x 300, 3채널로 설정되어 있으므로\n",
    "# 300 x 300 사이즈로 변환한다.\n",
    "a1 = cv2.resize(frame, (300,300))\n",
    "# cv2.imshow('a1',a1)\n",
    "\n",
    "# 2진 데이터로 변환한다,\n",
    "# 원본이미지 데이터, 스케일링(크기조정), 결과데이터 행렬 사이즈, 표준화를 위해\n",
    "# 각 색상에서 빼줄 색상값\n",
    "blob = cv2.dnn.blobFromImage(a1,1.0, (300,300), (104.0, 177.0, 123.0))\n",
    "\n",
    "# 학습모델에 데이터를 넣어준다.\n",
    "model.setInput(blob)\n",
    "\n",
    "# 얼굴 부분을 인식한다.\n",
    "dectections = model.forward()\n",
    "# 3번째 값이 얼굴이라고 인식된 부분의 개수\n",
    "#print(dectections.shape[2])\n",
    "\n",
    "# 얼굴이라고 인식된 부분의 개수만큼 반복한다.\n",
    "for i in range(dectections.shape[2]):\n",
    "    # 얼굴이라고 인지한 예측 정확도 추출\n",
    "    confidence = dectections[0,0,i,2]\n",
    "    # print(confidence)\n",
    "    \n",
    "    # 정해놓은 최소 정확도보다 높은것만 사용한다.\n",
    "    if confidence > min_confidence: \n",
    "        # 얼굴이라고 인식된 영역의 데이터를 추출한다.\n",
    "        box1 = dectections[0,0,i,3:7]\n",
    "        # print(box1)\n",
    "\n",
    "        # 원본 이미지에 맞게끔 좌표 계산을 해준다.\n",
    "        box2 = box1 * np.array([width, height, width, height])\n",
    "        # print(box2)\n",
    "        # 좌표를 정수형태로 변환한다.\n",
    "        x1, y1, x2, y2 = box2.astype('int')\n",
    "        # print(x1,y1, x2,y2)\n",
    "\n",
    "        # 사각형을 그린다.\n",
    "        cv2.rectangle(frame, (x1,y1),(x2,y2), (0,255,0),2)\n",
    "        # 예측 정확도를 표시한다.\n",
    "        text = f'{int(confidence*100)}%'\n",
    "        cv2.putText(frame, text, (x1,y1-5), cv2.FONT_HERSHEY_SCRIPT_SIMPLEX, 0.5, (0,0,255),2)\n",
    "    \n",
    "cv2.imshow('dection', frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
