{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn-whitegrid') # sns에 흰색 그리드 유지\n",
    "import missingno # 결측치 시각화\n",
    "\n",
    "# KFold (교차 검증을 사용하기 위해)\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# 교차검증 함수\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# 학습 데이터와 검증 데이터로 나누는 함수\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 데이터 전처리\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 하이퍼 파라미터 튜닝\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 평가 함수\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 머신러닝 알고리즘 - 분류\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "# 머신러닝 알고리즘 - 회귀\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from xgboost import  XGBRegressor\n",
    "\n",
    "# 머신러닝 알고리즘 - 군집\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import MeanShift\n",
    "\n",
    "# 머신러닝 알고리즘 - 차원축소\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "# 딥러닝 알고리즘 \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import tensorflow as tf\n",
    "\n",
    "# 다중분류를 위한 원핫 인코더\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# 학습 자동 중단\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# 모델 저장\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# 저장된 딥러닝 모델 불러오기\n",
    "from keras.models import load_model\n",
    "\n",
    "# 딥러닝\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers import MaxPooling1D\n",
    "\n",
    "# 자연어 처리\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# 저장\n",
    "import pickle\n",
    "\n",
    "# 시간 모듈\n",
    "import time\n",
    "\n",
    "# 그래프 설정\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'   # 윈도우용\n",
    "# plt.rcParams['font.family'] = 'AppleGothic'   # 맥용\n",
    "plt.rcParams['font.size'] = 10                 # 폰트 크기\n",
    "plt.rcParams['figure.figsize'] = 10,8          # 그래프 크기\n",
    "plt.rcParams['axes.unicode_minus'] = False     # - 기호 깨짐 방지\n",
    "\n",
    "\n",
    "# 경고 메시지가 안나오게 하기\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# gpu 사용 초기화 및 할당\n",
    "gpus= tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed 설정\n",
    "np.random.seed(3)\n",
    "tf.random.set_seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>평점</th>\n",
       "      <th>평가글</th>\n",
       "      <th>작성자</th>\n",
       "      <th>작성날짜</th>\n",
       "      <th>공감수</th>\n",
       "      <th>비공감수</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>B급 이하전편보다 퇴보된 CG, 중구난방식 연출, 러닝타임 늘리기 위한 쓸모없는 컷...</td>\n",
       "      <td>코꾸뇨우옹(pott****)</td>\n",
       "      <td>2020.12.24 09:08</td>\n",
       "      <td>873.0</td>\n",
       "      <td>289.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>이딴 영화가 평점 8점 후반대라는 게 믿기지 않는다. 역시 네이버 평점은 믿고 걸러...</td>\n",
       "      <td>juum****</td>\n",
       "      <td>2020.12.23 22:19</td>\n",
       "      <td>620.0</td>\n",
       "      <td>232.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.0</td>\n",
       "      <td>역시 원더우먼 영화는 주연배우 갤가돗과 크리스파인이 다 살리네.. 감독은 확실히 영...</td>\n",
       "      <td>없음(jymi****)</td>\n",
       "      <td>2020.12.23 17:05</td>\n",
       "      <td>480.0</td>\n",
       "      <td>168.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>진짜 개노잼이다.. 1편이랑 같은 감독맞나?러닝타임도 길어서 개지루함 ㄹㅇ</td>\n",
       "      <td>민중의빠따(gkst****)</td>\n",
       "      <td>2020.12.23 22:51</td>\n",
       "      <td>433.0</td>\n",
       "      <td>143.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>히어로물의 액션을 기대했음. 그러나 졸렬한 액션과 이상한 전개로 마지막 영화관을 나...</td>\n",
       "      <td>시리우스(sojh****)</td>\n",
       "      <td>2020.12.23 13:34</td>\n",
       "      <td>412.0</td>\n",
       "      <td>198.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    평점                                                평가글              작성자  \\\n",
       "0  1.0  B급 이하전편보다 퇴보된 CG, 중구난방식 연출, 러닝타임 늘리기 위한 쓸모없는 컷...  코꾸뇨우옹(pott****)   \n",
       "1  3.0  이딴 영화가 평점 8점 후반대라는 게 믿기지 않는다. 역시 네이버 평점은 믿고 걸러...         juum****   \n",
       "2  6.0  역시 원더우먼 영화는 주연배우 갤가돗과 크리스파인이 다 살리네.. 감독은 확실히 영...     없음(jymi****)   \n",
       "3  2.0          진짜 개노잼이다.. 1편이랑 같은 감독맞나?러닝타임도 길어서 개지루함 ㄹㅇ  민중의빠따(gkst****)   \n",
       "4  1.0  히어로물의 액션을 기대했음. 그러나 졸렬한 액션과 이상한 전개로 마지막 영화관을 나...   시리우스(sojh****)   \n",
       "\n",
       "               작성날짜    공감수   비공감수  \n",
       "0  2020.12.24 09:08  873.0  289.0  \n",
       "1  2020.12.23 22:19  620.0  232.0  \n",
       "2  2020.12.23 17:05  480.0  168.0  \n",
       "3  2020.12.23 22:51  433.0  143.0  \n",
       "4  2020.12.23 13:34  412.0  198.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터를 읽어온다.\n",
    "df1 = pd.read_csv('../dataset/naver_star_data.csv')\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>평점</th>\n",
       "      <th>평가글</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>B급 이하전편보다 퇴보된 CG, 중구난방식 연출, 러닝타임 늘리기 위한 쓸모없는 컷...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>이딴 영화가 평점 8점 후반대라는 게 믿기지 않는다. 역시 네이버 평점은 믿고 걸러...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.0</td>\n",
       "      <td>역시 원더우먼 영화는 주연배우 갤가돗과 크리스파인이 다 살리네.. 감독은 확실히 영...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>진짜 개노잼이다.. 1편이랑 같은 감독맞나?러닝타임도 길어서 개지루함 ㄹㅇ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>히어로물의 액션을 기대했음. 그러나 졸렬한 액션과 이상한 전개로 마지막 영화관을 나...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    평점                                                평가글\n",
       "0  1.0  B급 이하전편보다 퇴보된 CG, 중구난방식 연출, 러닝타임 늘리기 위한 쓸모없는 컷...\n",
       "1  3.0  이딴 영화가 평점 8점 후반대라는 게 믿기지 않는다. 역시 네이버 평점은 믿고 걸러...\n",
       "2  6.0  역시 원더우먼 영화는 주연배우 갤가돗과 크리스파인이 다 살리네.. 감독은 확실히 영...\n",
       "3  2.0          진짜 개노잼이다.. 1편이랑 같은 감독맞나?러닝타임도 길어서 개지루함 ㄹㅇ\n",
       "4  1.0  히어로물의 액션을 기대했음. 그러나 졸렬한 액션과 이상한 전개로 마지막 영화관을 나..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df1[['평점','평가글']]\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>평점</th>\n",
       "      <th>평가글</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>너무나 판타지스러우면서도 마지막은 현실적이라 좀 마음이 찜찜하다. 정말 재밌게 봤다...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.0</td>\n",
       "      <td>씨지가 많이 발전햇네요후반부에 눈물 무쟈게 흘리고 나왓네요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>그냥 거기서거기인듯 원작과는 정말 많이 다르고 CG는 생각보다 이상하진 않았지만  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0</td>\n",
       "      <td>감히 내사랑을!!!!! 그렇지. 누구라도 한눈에 반해버린 내사랑을 건드림 뚜껑 열린...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.0</td>\n",
       "      <td>우는 장면에서는 왜 우는지 이해는 안되지만 그래도 예쁘고 여운이 남는 작품이었다!스...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     평점                                                평가글\n",
       "0  10.0  너무나 판타지스러우면서도 마지막은 현실적이라 좀 마음이 찜찜하다. 정말 재밌게 봤다...\n",
       "1  10.0                   씨지가 많이 발전햇네요후반부에 눈물 무쟈게 흘리고 나왓네요\n",
       "2   4.0  그냥 거기서거기인듯 원작과는 정말 많이 다르고 CG는 생각보다 이상하진 않았지만  ...\n",
       "3  10.0  감히 내사랑을!!!!! 그렇지. 누구라도 한눈에 반해버린 내사랑을 건드림 뚜껑 열린...\n",
       "4   9.0  우는 장면에서는 왜 우는지 이해는 안되지만 그래도 예쁘고 여운이 남는 작품이었다!스..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 테스트용 코드 - 학습령이 너무 많기 때문에 랜덤하게 500개만 추출\n",
    "df3 = df2.sample(n=500, random_state=2).reset_index(drop=True)\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "평점      0\n",
       "평가글    15\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결측치 확인\n",
    "df3.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "평점     0\n",
       "평가글    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결측치 제거\n",
    "df3.dropna(inplace=True)\n",
    "df3.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 글 인덱스를 평점을 기준으로 나눠서 추출한다.\n",
    "a1 = df3.query('평점 <= 5').index\n",
    "a2 = df3.query('평점 > 5').index\n",
    "\n",
    "# 새로운 값을 세팅한다 (0:부정, 1:긍정)\n",
    "df3.loc[a1, '평점'] = 0\n",
    "df3.loc[a2, '평점'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    416\n",
       "0.0     69\n",
       "Name: 평점, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3['평점'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 분리한다.\n",
    "docs = df3['평가글'].values\n",
    "classes = df3['평점'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 단어 사전을 생성한다.\n",
    "token = Tokenizer()\n",
    "token.fit_on_texts(docs)\n",
    "token.word_index['영화']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[149,\n",
       " 547,\n",
       " 548,\n",
       " 549,\n",
       " 9,\n",
       " 93,\n",
       " 550,\n",
       " 4,\n",
       " 17,\n",
       " 150,\n",
       " 551,\n",
       " 151,\n",
       " 552,\n",
       " 243,\n",
       " 553,\n",
       " 42,\n",
       " 554,\n",
       " 555]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 생성한 단어사전을 기준으로 단어들을 숫자로 표현한다.\n",
    "x = token.texts_to_sequences(docs)\n",
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문장당 최대 단어 개수를 구한다.\n",
    "max_length = 0\n",
    "\n",
    "for str1 in x:\n",
    "    # 현재 문장의 단어수를 가져온다.\n",
    "    a1 = len(str1)\n",
    "    \n",
    "    # 현재 문장의 단어수가 이전 최대 단어수보다 크면 \n",
    "    # 값을 덮어씌운다.\n",
    "    if max_length < a1:\n",
    "        max_length = a1\n",
    "        \n",
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,   42,  554,  555],\n",
       "       [   0,    0,    0, ...,  558,  559,  560],\n",
       "       [   0,    0,    0, ...,  246,  570,  247],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,   99, 3170, 3171],\n",
       "       [   0,    0,    0, ..., 3176,   51, 3177],\n",
       "       [   0,    0,    0, ..., 3182, 3183, 3184]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 패딩, 서로 길이가 다른 리스트(단어수)의 개수를 맞춰준다.\n",
    "# 부족한 부분을 0으로 채워준다.\n",
    "padded_x = pad_sequences(x, max_length)\n",
    "padded_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3185"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 단어의 개수에 1을 더한 값을 구한다.\n",
    "word_size = len(token.word_index) + 1\n",
    "word_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 데이터를 나눈다.\n",
    "X_train, X_test, y_train, y_test  = train_test_split(padded_x, classes, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 설정\n",
    "model = Sequential()\n",
    "model.add(Embedding(word_size, 100))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv1D(64,5,padding='valid', activation='relu', strides=1))\n",
    "model.add(MaxPooling1D(pool_size=4))\n",
    "model.add(LSTM(55))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 100)         318500    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, None, 100)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, None, 64)          32064     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, None, 64)          0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 55)                26400     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 56        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 377,020\n",
      "Trainable params: 377,020\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 정보\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 컴파일\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "4/4 [==============================] - 11s 197ms/step - loss: 0.6865 - accuracy: 0.5127 - val_loss: 0.6309 - val_accuracy: 0.8699\n",
      "Epoch 2/5\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.5952 - accuracy: 0.8637 - val_loss: 0.5355 - val_accuracy: 0.8699\n",
      "Epoch 3/5\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4970 - accuracy: 0.8490 - val_loss: 0.4245 - val_accuracy: 0.8699\n",
      "Epoch 4/5\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.4191 - accuracy: 0.8480 - val_loss: 0.3889 - val_accuracy: 0.8699\n",
      "Epoch 5/5\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4322 - accuracy: 0.8417 - val_loss: 0.3988 - val_accuracy: 0.8699\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1fd4be62370>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습시작\n",
    "model.fit(X_train, y_train, validation_data = (X_test, y_test), batch_size=100, epochs=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
